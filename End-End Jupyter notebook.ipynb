{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Multi-Dimensional Candidate Matching System for Any Job Posting**"
      ],
      "metadata": {
        "id": "hfKCl_VssA2W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Installations**"
      ],
      "metadata": {
        "id": "6lY_MsFnKCA9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEB104aq7ZOl",
        "outputId": "8849a68d-fc95-4b5b-f5ac-3431f68bc9b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing required libraries...\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.17.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.17.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m125.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstallation complete.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Installing required libraries...\")\n",
        "!pip install openai -q\n",
        "!pip install pydantic -q\n",
        "!pip install sentence-transformers -q\n",
        "!pip install rank-bm25 -q\n",
        "!pip install chromadb -q\n",
        "!pip install tenacity -q\n",
        "!pip install pdfplumber -q\n",
        "!pip install python-docx -q\n",
        "!pip install streamlit -q\n",
        "!pip install pyngrok -q\n",
        "!pip install numpy -q\n",
        "print(\"Installation complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Imports & API Key**"
      ],
      "metadata": {
        "id": "P6EgUKlgKLuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import json\n",
        "import pdfplumber\n",
        "import docx\n",
        "import re\n",
        "import numpy as np\n",
        "from getpass import getpass\n",
        "\n",
        "OPENROUTER_API_KEY = getpass(\"Enter your OpenRouter API Key: \")\n",
        "os.environ['OPENROUTER_API_KEY'] = OPENROUTER_API_KEY\n",
        "\n",
        "print(\"API Key set.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZBsJLcb7kug",
        "outputId": "55b90533-fcf9-4233-8acd-cd41663a7def"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your OpenRouter API Key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "API Key set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **config.py**"
      ],
      "metadata": {
        "id": "i37oDLeIKWF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile config.py\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Dict\n",
        "\n",
        "LLM_PARSING_MODEL = \"mistralai/mistral-7b-instruct:free\"\n",
        "LLM_EXPLAIN_MODEL = \"mistralai/mistral-7b-instruct:free\"\n",
        "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
        "\n",
        "TOP_K_RETRIEVAL = 10\n",
        "\n",
        "SCORING_WEIGHTS = {\n",
        "    \"must_have_skills\": 0.35,\n",
        "    \"important_skills\": 0.25,\n",
        "    \"nice_to_have_skills\": 0.10,\n",
        "    \"experience_relevance\": 0.15,\n",
        "    \"recency\": 0.10,\n",
        "    \"domain_match\": 0.05\n",
        "}\n",
        "\n",
        "\n",
        "class SkillCluster(BaseModel):\n",
        "    must_have: List[str]\n",
        "    important: List[str]\n",
        "    nice_to_have: List[str]\n",
        "    implicit_skills: List[str]\n",
        "\n",
        "class ParsedJob(BaseModel):\n",
        "    job_title: str\n",
        "    required_years_experience: int\n",
        "    skills: SkillCluster\n",
        "    domain_keywords: List[str] = Field(default_factory=list, description=\"Industry keywords (e.g., 'FinTech', 'Healthcare')\")\n",
        "    responsibilities_summary: str\n",
        "\n",
        "class ExperienceEntry(BaseModel):\n",
        "    title: str\n",
        "    company: str\n",
        "    start_date: str\n",
        "    end_date: str\n",
        "    description: str\n",
        "\n",
        "class ParsedResume(BaseModel):\n",
        "    name: str\n",
        "    total_years_experience: int\n",
        "    skills: List[str]\n",
        "    education: List[str] = Field(default_factory=list, description=\"Degrees or certifications (e.g., 'B.S. in Computer Science')\")\n",
        "    domain_keywords: List[str] = Field(default_factory=list, description=\"Industry keywords (e.g., 'FinTech', 'E-commerce')\")\n",
        "    experience: List[ExperienceEntry]\n",
        "    full_text_summary: str\n",
        "\n",
        "class Explanation(BaseModel):\n",
        "    overall_fit_score: int = Field(..., description=\"The final score from 0-100\")\n",
        "    confidence: str = Field(..., description=\"High, Medium, or Low\")\n",
        "    strengths: str = Field(..., description=\"A string (use bullet points) of what the candidate matches well.\")\n",
        "    gaps: str = Field(..., description=\"A string (use bullet points) of what the candidate seems to be missing.\")\n",
        "    notes: str = Field(..., description=\"A brief, overall recommendation.\")\n",
        "\n",
        "\n",
        "# -System Prompts -\n",
        "PROMPT_PARSE_JOB = \"\"\"\n",
        "You are an expert JSON-generating HR analyst. You must analyze the job posting\n",
        "and return *only* a valid JSON object. The JSON object must strictly\n",
        "adhere to the following Pydantic JSON Schema:\n",
        "\n",
        "```json\n",
        "{schema}\n",
        "```\n",
        "\n",
        "Job Posting Text:\n",
        "---\n",
        "{job_text}\n",
        "---\n",
        "\n",
        "Respond *only* with the JSON. Do not add any other text.\n",
        "\"\"\"\n",
        "\n",
        "PROMPT_PARSE_RESUME = \"\"\"\n",
        "You are an expert JSON-generating resume parser. You must analyze the resume\n",
        "and return *only* a valid JSON object. The JSON object must strictly\n",
        "adhere to the following Pydantic JSON Schema:\n",
        "\n",
        "```json\n",
        "{schema}\n",
        "```\n",
        "\n",
        "Resume Text:\n",
        "---\n",
        "{resume_text}\n",
        "---\n",
        "\n",
        "Respond *only* with the JSON. Do not add any other text.\n",
        "\"\"\"\n",
        "\n",
        "PROMPT_EXPLAIN_MATCH = \"\"\"\n",
        "You are a helpful recruiting assistant. A job posting and a candidate's profile\n",
        "have been scored across 6 dimensions. Your job is to generate a final report\n",
        "as a JSON object.\n",
        "\n",
        "**Data:**\n",
        "- Job Summary: {job_summary}\n",
        "- Resume Summary: {resume_summary}\n",
        "- Score (Must-Have): {must_have_score}/100\n",
        "- Score (Important): {important_score}/100\n",
        "- Score (Experience): {experience_score}/100\n",
        "- Score (Recency): {recency_score}/100\n",
        "- Score (Domain): {domain_score}/100\n",
        "- Final Score: {final_score}/100\n",
        "\n",
        "Your task is to generate a final report for the hiring manager.\n",
        "The report must be a JSON object with 5 keys:\n",
        "'overall_fit_score' (int), 'confidence' (string), 'strengths' (string),\n",
        "'gaps' (string), and 'notes' (string).\n",
        "\"\"\"\n",
        "print(\"File 'config.py' created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew7epMPX72Nq",
        "outputId": "a61873e7-764f-4c1c-97e8-00a90c44906f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing config.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **llm_interface.py**"
      ],
      "metadata": {
        "id": "vnyCLoJ5KlX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile llm_interface.py\n",
        "\n",
        "import os\n",
        "import json\n",
        "from openai import OpenAI\n",
        "from pydantic import BaseModel\n",
        "from typing import Type\n",
        "import config\n",
        "\n",
        "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n",
        ")\n",
        "\n",
        "\n",
        "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(3))\n",
        "def robust_llm_call(prompt: str, response_model: Type[BaseModel], model: str):\n",
        "    \"\"\"\n",
        "    A robust function to call an LLM and parse the output into a Pydantic model\n",
        "    using 'response_format'.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"LLM Call: Pydantic parsing with {model}...\")\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            response_format={\"type\": \"json_object\"}\n",
        "        )\n",
        "\n",
        "        content = response.choices[0].message.content\n",
        "        arguments = json.loads(content)\n",
        "\n",
        "        return response_model.model_validate(arguments)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in LLM call or JSON parsing: {e}\")\n",
        "        print(f\"Model: {model}, Prompt: {prompt[:100]}...\")\n",
        "        raise e\n",
        "\n",
        "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(3))\n",
        "def generative_llm_call(prompt: str, model: str):\n",
        "    \"\"\"\n",
        "    A robust function for a simple generative LLM call expecting JSON.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"LLM Call: Generative explanation with {model}...\")\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            response_format={\"type\": \"json_object\"}\n",
        "        )\n",
        "        return json.loads(response.choices[0].message.content)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in generative LLM call: {e}\")\n",
        "        raise e\n",
        "\n",
        "def parse_job_posting(job_text: str) -> config.ParsedJob:\n",
        "    \"\"\"Uses LLM to structure a job posting.\"\"\"\n",
        "    schema = config.ParsedJob.model_json_schema()\n",
        "    prompt = config.PROMPT_PARSE_JOB.format(\n",
        "        schema=json.dumps(schema, indent=2),\n",
        "        job_text=job_text\n",
        "    )\n",
        "    return robust_llm_call(prompt, config.ParsedJob, config.LLM_PARSING_MODEL)\n",
        "\n",
        "def parse_resume(resume_text: str) -> config.ParsedResume:\n",
        "    \"\"\"Uses LLM to structure a resume.\"\"\"\n",
        "    schema = config.ParsedResume.model_json_schema()\n",
        "    prompt = config.PROMPT_PARSE_RESUME.format(\n",
        "        schema=json.dumps(schema, indent=2),\n",
        "        resume_text=resume_text\n",
        "    )\n",
        "    return robust_llm_call(prompt, config.ParsedResume, config.LLM_PARSING_MODEL)\n",
        "\n",
        "def generate_explanation(report_data: dict) -> dict:\n",
        "    \"\"\"Uses LLM to generate the final human-readable report.\"\"\"\n",
        "    prompt = config.PROMPT_EXPLAIN_MATCH.format(**report_data)\n",
        "\n",
        "    try:\n",
        "        explanation_json = generative_llm_call(prompt, config.LLM_EXPLAIN_MODEL)\n",
        "        report_data.update(explanation_json)\n",
        "        return report_data\n",
        "    except Exception as e:\n",
        "        print(f\"Error in explanation LLM call (final attempt failed): {e}\")\n",
        "        report_data.update({\n",
        "            \"strengths\": \"Error generating AI analysis.\",\n",
        "            \"gaps\": \"Error generating AI analysis.\",\n",
        "            \"notes\": \"System error.\"\n",
        "        })\n",
        "        return report_data\n",
        "\n",
        "print(\"File 'llm_interface.py' (Final Version with Import Fix) created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc1FskC28ktb",
        "outputId": "fd3b6454-4453-462b-e0a5-3fb19210e8ec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing llm_interface.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **scoring.py**"
      ],
      "metadata": {
        "id": "JKUshO8DLFeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile scoring.py\n",
        "\n",
        "import config\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "class ScoringEngine:\n",
        "    def __init__(self):\n",
        "        self.weights = config.SCORING_WEIGHTS\n",
        "        print(\"ScoringEngine initialized.\")\n",
        "\n",
        "    def _score_skills(self, required: list, candidate_keywords: list) -> float:\n",
        "        \"\"\"\n",
        "        --- CORRECTED LOGIC ---\n",
        "        Scores skill match from 0 to 100.\n",
        "        Checks if any candidate keyword (e.g., \"Python\", \"B.S. in CS\") exists\n",
        "        inside the job requirement phrase (e.g., \"5+ years of Python experience\").\n",
        "        \"\"\"\n",
        "        if not required:\n",
        "            return 100.0\n",
        "\n",
        "        matched_count = 0\n",
        "        candidate_keywords_lower = [s.lower() for s in candidate_keywords]\n",
        "\n",
        "        for req_phrase in required:\n",
        "            req_phrase_lower = req_phrase.lower()\n",
        "            for skill_keyword in candidate_keywords_lower:\n",
        "                if skill_keyword in req_phrase_lower:\n",
        "                    matched_count += 1\n",
        "                    break\n",
        "\n",
        "        return (matched_count / len(required)) * 100\n",
        "\n",
        "    def _score_experience(self, required_years: int, candidate_years: int) -> float:\n",
        "        \"\"\"Scores experience match from 0 to 100 (capped at 100).\"\"\"\n",
        "        if required_years == 0:\n",
        "            return 100.0\n",
        "\n",
        "        if candidate_years >= required_years:\n",
        "            return 100.0\n",
        "        else:\n",
        "            return (candidate_years / required_years) * 100\n",
        "\n",
        "    def _score_recency(self, experience_entries: list) -> float:\n",
        "        \"\"\"Scores recency. 100 if a job ended in the last 2 years or is 'Present'.\"\"\"\n",
        "        if not experience_entries:\n",
        "            return 0.0\n",
        "\n",
        "        today = datetime.today()\n",
        "        for entry_data in experience_entries:\n",
        "            end_date = entry_data.get('end_date', '').lower()\n",
        "            if end_date == 'present':\n",
        "                return 100.0\n",
        "\n",
        "            try:\n",
        "                end_year_match = re.search(r'(\\d{4})', end_date)\n",
        "                if end_year_match:\n",
        "                    end_year = int(end_year_match.group(1))\n",
        "                    if (today.year - end_year) <= 2:\n",
        "                        return 100.0\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        return 30.0\n",
        "\n",
        "    def _score_domain(self, job_keywords: list, resume_keywords: list) -> float:\n",
        "        \"\"\"\n",
        "        --- NEW, ROBUST LOGIC ---\n",
        "        Scores domain match. Checks for any overlap between keyword lists.\n",
        "        \"\"\"\n",
        "        if not job_keywords:\n",
        "            return 50.0\n",
        "\n",
        "        job_set = set(k.lower() for k in job_keywords)\n",
        "        resume_set = set(k.lower() for k in resume_keywords)\n",
        "\n",
        "        if job_set.intersection(resume_set):\n",
        "            return 100.0\n",
        "        else:\n",
        "            return 0.0\n",
        "\n",
        "    def score_candidate(self, job: config.ParsedJob, resume: config.ParsedResume) -> dict:\n",
        "        \"\"\"Runs the full 6-dimension scoring for a single candidate.\"\"\"\n",
        "        print(f\"Re-ranking candidate: {resume.name}\")\n",
        "\n",
        "        job_skills = job.skills.model_dump()\n",
        "        resume_experience = [exp.model_dump() for exp in resume.experience]\n",
        "\n",
        "        candidate_keywords = resume.skills + resume.education\n",
        "\n",
        "        scores = {\n",
        "            \"must_have_score\": self._score_skills(job_skills['must_have'], candidate_keywords),\n",
        "            \"important_score\": self._score_skills(job_skills['important'], candidate_keywords),\n",
        "            \"nice_to_have_score\": self._score_skills(job_skills['nice_to_have'], candidate_keywords),\n",
        "            \"experience_score\": self._score_experience(job.required_years_experience, resume.total_years_experience),\n",
        "            \"recency_score\": self._score_recency(resume_experience),\n",
        "            \"domain_score\": self._score_domain(job.domain_keywords, resume.domain_keywords)\n",
        "        }\n",
        "\n",
        "        final_score = (\n",
        "            scores[\"must_have_score\"] * self.weights[\"must_have_skills\"] +\n",
        "            scores[\"important_score\"] * self.weights[\"important_skills\"] +\n",
        "            scores[\"nice_to_have_score\"] * self.weights[\"nice_to_have_skills\"] +\n",
        "            scores[\"experience_score\"] * self.weights[\"experience_relevance\"] +\n",
        "            scores[\"recency_score\"] * self.weights[\"recency\"] +\n",
        "            scores[\"domain_score\"] * self.weights[\"domain_match\"]\n",
        "        )\n",
        "\n",
        "        report_data = {\n",
        "            \"name\": resume.name,\n",
        "            \"final_score\": round(final_score, 2),\n",
        "            \"job_summary\": job.responsibilities_summary,\n",
        "            \"resume_summary\": resume.full_text_summary,\n",
        "            **scores\n",
        "        }\n",
        "\n",
        "        return report_data\n",
        "\n",
        "print(\"File 'scoring.py' (Final Version with Corrected Logic) created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghYlxnbz8ons",
        "outputId": "e271253e-a727-4157-ce55-31d887a0ea51"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing scoring.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **utils.py**"
      ],
      "metadata": {
        "id": "tUMZrnamLN7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile utils.py\n",
        "\n",
        "import pdfplumber\n",
        "import docx\n",
        "import os\n",
        "import re\n",
        "from typing import List, Union\n",
        "\n",
        "def extract_text(file_path: str) -> Union[str, None]:\n",
        "    \"\"\"Extracts text from PDF, DOCX, or TXT.\"\"\"\n",
        "    print(f\"Extracting text from: {file_path}\")\n",
        "    _, extension = os.path.splitext(file_path)\n",
        "\n",
        "    try:\n",
        "        if extension == '.pdf':\n",
        "            with pdfplumber.open(file_path) as pdf:\n",
        "                return \"\\n\".join(page.extract_text() for page in pdf.pages)\n",
        "        elif extension == '.docx':\n",
        "            doc = docx.Document(file_path)\n",
        "            return \"\\n\".join(para.text for para in doc.paragraphs)\n",
        "        elif extension == '.txt':\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                return f.read()\n",
        "        else:\n",
        "            print(f\"Warning: Unsupported file type: {file_path}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def simple_tokenizer(text: str) -> List[str]:\n",
        "    \"\"\"A simple tokenizer for BM25.\"\"\"\n",
        "    text = re.sub(r'[^\\w\\s]', '', text).lower()\n",
        "    return text.split()\n",
        "\n",
        "print(\"File 'utils.py' created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk1xzAuk8sTn",
        "outputId": "8a707ad3-2e57-4b21-fc8d-91b6ca1e057b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **retrieval.py**"
      ],
      "metadata": {
        "id": "B_j9_UrILVN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile retrieval.py\n",
        "\n",
        "from rank_bm25 import BM25Okapi\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import config\n",
        "from utils import simple_tokenizer\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "\n",
        "class HybridRetriever:\n",
        "    def __init__(self):\n",
        "        self.bm25_index = None\n",
        "        self.corpus_ids = []\n",
        "\n",
        "        self.sbert_model = SentenceTransformer(config.EMBEDDING_MODEL)\n",
        "\n",
        "        self.chroma_client = chromadb.Client()\n",
        "\n",
        "        self.embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
        "            model_name=config.EMBEDDING_MODEL\n",
        "        )\n",
        "\n",
        "        self.collection = self.chroma_client.get_or_create_collection(\n",
        "            name=\"resume_collection\",\n",
        "            embedding_function=self.embedding_func\n",
        "        )\n",
        "        print(\"HybridRetriever initialized with ChromaDB.\")\n",
        "\n",
        "    def index(self, corpus: list[str], corpus_ids: list[str]):\n",
        "        \"\"\"Creates the BM25 and ChromaDB indexes.\"\"\"\n",
        "        if not corpus:\n",
        "            print(\"Warning: No documents to index.\")\n",
        "            return\n",
        "\n",
        "        print(f\"Indexing {len(corpus)} documents...\")\n",
        "        self.corpus_ids = corpus_ids\n",
        "\n",
        "        tokenized_corpus = [simple_tokenizer(doc) for doc in corpus]\n",
        "        self.bm25_index = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "\n",
        "        existing_ids = self.collection.get()['ids']\n",
        "        if existing_ids:\n",
        "            print(f\"Clearing {len(existing_ids)} old items from ChromaDB.\")\n",
        "            self.collection.delete(ids=existing_ids)\n",
        "\n",
        "        self.collection.add(\n",
        "            documents=corpus,\n",
        "            ids=corpus_ids\n",
        "        )\n",
        "        print(\"Indexing complete.\")\n",
        "\n",
        "    def search(self, query: str, top_k: int) -> list[str]:\n",
        "        \"\"\"\n",
        "        Performs hybrid search.\n",
        "        1. Gets top_k from Sparse (BM25).\n",
        "        2. Gets top_k from Dense (Chroma).\n",
        "        3. Returns the UNION of the two lists.\n",
        "        \"\"\"\n",
        "        if self.bm25_index is None:\n",
        "            raise Exception(\"Must call .index() before .search()\")\n",
        "\n",
        "        print(f\"Running hybrid search for query: {query[:50]}...\")\n",
        "\n",
        "        tokenized_query = simple_tokenizer(query)\n",
        "        bm25_scores = self.bm25_index.get_scores(tokenized_query)\n",
        "\n",
        "        bm25_top_indices = np.argsort(bm25_scores)[::-1][:top_k]\n",
        "        sparse_ids = [self.corpus_ids[i] for i in bm25_top_indices]\n",
        "        print(f\"BM25 found IDs: {sparse_ids}\")\n",
        "\n",
        "        dense_results = self.collection.query(\n",
        "            query_texts=[query],\n",
        "            n_results=top_k\n",
        "        )\n",
        "        dense_ids = dense_results['ids'][0]\n",
        "        print(f\"ChromaDB found IDs: {dense_ids}\")\n",
        "\n",
        "        fused_ids = list(set(sparse_ids) | set(dense_ids))\n",
        "\n",
        "        print(f\"Retrieval found {len(fused_ids)} unique candidates for re-ranking.\")\n",
        "        return fused_ids\n",
        "\n",
        "print(\"File 'retrieval.py' (Upgraded with ChromaDB Fix) created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgEAz4MF8v_u",
        "outputId": "7072e920-37e7-40e6-c8d4-78a241543a4f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing retrieval.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **matching_system.py**"
      ],
      "metadata": {
        "id": "whrFxX7nLcaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matching_system.py\n",
        "\n",
        "# The main orchestrator class that runs the full pipeline.\n",
        "\n",
        "import utils\n",
        "import llm_interface\n",
        "from retrieval import HybridRetriever\n",
        "from scoring import ScoringEngine\n",
        "import config\n",
        "from typing import List\n",
        "import traceback\n",
        "\n",
        "class CandidateMatchingSystem:\n",
        "    def __init__(self):\n",
        "        self.job = None\n",
        "        self.candidates_db = {}\n",
        "        self.retriever = HybridRetriever()\n",
        "        self.scorer = ScoringEngine()\n",
        "        print(\"CandidateMatchingSystem initialized.\")\n",
        "\n",
        "    def process_job_posting(self, job_file: str):\n",
        "        \"\"\"Loads and parses the job posting.\"\"\"\n",
        "        job_text = utils.extract_text(job_file)\n",
        "        if not job_text:\n",
        "            raise Exception(\"Job posting file is empty or unreadable.\")\n",
        "\n",
        "        self.job = llm_interface.parse_job_posting(job_text)\n",
        "        if not self.job:\n",
        "            raise Exception(\"LLM failed to parse job posting.\")\n",
        "\n",
        "        print(f\"Successfully parsed job: {self.job.job_title}\")\n",
        "\n",
        "    def process_resumes(self, resume_files: List[str]):\n",
        "        \"\"\"Loads and parses all candidate resumes.\"\"\"\n",
        "        self.candidates_db = {}\n",
        "\n",
        "        print(f\"Starting processing for {len(resume_files)} resumes...\")\n",
        "\n",
        "        for f in resume_files:\n",
        "            try:\n",
        "                print(f\"Processing file: {f}\")\n",
        "                resume_text = utils.extract_text(f)\n",
        "                if not resume_text:\n",
        "                    print(f\"Skipping empty or unreadable file: {f}\")\n",
        "                    continue\n",
        "\n",
        "                parsed_resume = llm_interface.parse_resume(resume_text)\n",
        "                if parsed_resume:\n",
        "                    file_id = f.split('/')[-1]\n",
        "                    self.candidates_db[file_id] = parsed_resume\n",
        "                    print(f\"Successfully parsed: {file_id}\")\n",
        "                else:\n",
        "                    print(f\"LLM failed to parse resume: {f}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing resume {f}: {str(e)}\")\n",
        "                traceback.print_exc()\n",
        "                continue\n",
        "\n",
        "        print(f\"Successfully parsed {len(self.candidates_db)} out of {len(resume_files)} resumes.\")\n",
        "\n",
        "    def run_matching_pipeline(self) -> List[dict]:\n",
        "        \"\"\"\n",
        "        Runs the full retrieve -> re-rank -> explain pipeline.\n",
        "        \"\"\"\n",
        "        if not self.job or not self.candidates_db:\n",
        "            raise Exception(\"Job and resumes must be processed first.\")\n",
        "\n",
        "        corpus = [res.full_text_summary for res in self.candidates_db.values()]\n",
        "        corpus_ids = list(self.candidates_db.keys())\n",
        "\n",
        "        if not corpus:\n",
        "             return []\n",
        "\n",
        "        self.retriever.index(corpus, corpus_ids)\n",
        "\n",
        "\n",
        "        k_to_retrieve = min(len(corpus_ids), config.TOP_K_RETRIEVAL)\n",
        "        query = self.job.responsibilities_summary\n",
        "\n",
        "        candidate_ids_to_rank = self.retriever.search(query, top_k=k_to_retrieve)\n",
        "\n",
        "        print(f\"Re-ranking {len(candidate_ids_to_rank)} candidates...\")\n",
        "\n",
        "        reports = []\n",
        "        for candidate_id in candidate_ids_to_rank:\n",
        "            candidate = self.candidates_db.get(candidate_id)\n",
        "            if not candidate:\n",
        "                print(f\"Warning: Could not find candidate for ID {candidate_id}\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                report = self.scorer.score_candidate(self.job, candidate)\n",
        "                report[\"filename\"] = candidate_id\n",
        "                reports.append(report)\n",
        "            except Exception as e:\n",
        "                print(f\"Error scoring candidate {candidate_id}: {e}\")\n",
        "                continue\n",
        "\n",
        "        explained_reports = []\n",
        "        for report in reports:\n",
        "            try:\n",
        "                explained_report = llm_interface.generate_explanation(report)\n",
        "                explained_reports.append(explained_report)\n",
        "            except Exception as e:\n",
        "                 print(f\"Error generating explanation for {report.get('filename')}: {e}\")\n",
        "                 explained_reports.append(report)\n",
        "\n",
        "        sorted_reports = sorted(explained_reports, key=lambda r: r['final_score'], reverse=True)\n",
        "\n",
        "        return sorted_reports\n",
        "\n",
        "print(\"File 'matching_system.py' (Final Robust Version) created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGOBZyQvHj1N",
        "outputId": "5dbb3634-1802-41e9-d4d0-864dabbe8321"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matching_system.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **app.py**"
      ],
      "metadata": {
        "id": "ID2yxpjMLiXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import os\n",
        "import importlib\n",
        "import time\n",
        "import sys\n",
        "\n",
        "sys.path.append(os.getcwd())\n",
        "\n",
        "# Set page config to wide mode and add a title/icon\n",
        "st.set_page_config(\n",
        "    page_title=\"TalentScout AI | Smart Hiring Assistant\",\n",
        "    page_icon=\"ğŸš€\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# --- Custom CSS for Professional Look ---\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "    .main {\n",
        "        background-color: #f8f9fa;\n",
        "    }\n",
        "    .stButton>button {\n",
        "        width: 100%;\n",
        "        border-radius: 5px;\n",
        "        height: 3em;\n",
        "        background-color: #4CAF50;\n",
        "        color: white;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    .stButton>button:hover {\n",
        "        background-color: #45a049;\n",
        "        border-color: #45a049;\n",
        "        color: white;\n",
        "    }\n",
        "    .report-card {\n",
        "        background-color: white;\n",
        "        padding: 20px;\n",
        "        border-radius: 10px;\n",
        "        box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
        "        margin-bottom: 20px;\n",
        "        border-left: 5px solid #4CAF50;\n",
        "    }\n",
        "    .metric-box {\n",
        "        background-color: #f1f3f4;\n",
        "        padding: 10px;\n",
        "        border-radius: 5px;\n",
        "        text-align: center;\n",
        "    }\n",
        "    h1, h2, h3 {\n",
        "        color: #2c3e50;\n",
        "    }\n",
        "    </style>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "def save_uploaded_file(uploaded_file, save_dir=\"data\"):\n",
        "    \"\"\"Saves an uploaded file to a directory.\"\"\"\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "\n",
        "    filename, ext = os.path.splitext(uploaded_file.name)\n",
        "    file_path = os.path.join(save_dir, f\"{filename}_{int(time.time())}{ext}\")\n",
        "\n",
        "    with open(file_path, \"wb\") as f:\n",
        "        f.write(uploaded_file.getbuffer())\n",
        "    return file_path\n",
        "\n",
        "@st.cache_resource\n",
        "def get_system():\n",
        "    \"\"\"Caches the main system class.\"\"\"\n",
        "    import config, utils, llm_interface, retrieval, scoring, matching_system\n",
        "    importlib.reload(config)\n",
        "    importlib.reload(utils)\n",
        "    importlib.reload(llm_interface)\n",
        "    importlib.reload(retrieval)\n",
        "    importlib.reload(scoring)\n",
        "    importlib.reload(matching_system)\n",
        "\n",
        "    from matching_system import CandidateMatchingSystem\n",
        "    return CandidateMatchingSystem()\n",
        "\n",
        "# --- 2. Sidebar (Configuration) ---\n",
        "with st.sidebar:\n",
        "    st.image(\"https://cdn-icons-png.flaticon.com/512/4712/4712009.png\", width=60)\n",
        "    st.title(\"TalentScout AI\")\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    st.subheader(\"1. Configuration\")\n",
        "    api_key = st.text_input(\"OpenRouter API Key\", type=\"password\", help=\"Enter your API key to enable the AI engine.\")\n",
        "    if api_key:\n",
        "        os.environ['OPENROUTER_API_KEY'] = api_key\n",
        "        st.success(\"âœ… API Key Connected\")\n",
        "\n",
        "    st.subheader(\"2. Job Details\")\n",
        "    job_file = st.file_uploader(\"Upload Job Description\", type=[\"pdf\", \"docx\", \"txt\"], help=\"Upload the JD to match candidates against.\")\n",
        "\n",
        "    st.subheader(\"3. Candidate Pool\")\n",
        "    resume_files = st.file_uploader(\"Upload Resumes\", type=[\"pdf\", \"docx\", \"txt\"], accept_multiple_files=True, help=\"Select multiple resumes to analyze.\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    run_button = st.button(\"ğŸš€ Start Matching Analysis\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.caption(\"Powered by Mistral 7B & Vector Search\")\n",
        "\n",
        "\n",
        "st.title(\"ğŸš€ AI Candidate Matching Dashboard\")\n",
        "st.markdown(\"### Intelligent ranking based on skills, experience, and semantic relevance.\")\n",
        "\n",
        "if run_button:\n",
        "    if not api_key:\n",
        "        st.warning(\"âš ï¸ Please enter your OpenRouter API Key in the sidebar to proceed.\")\n",
        "    elif not job_file:\n",
        "        st.warning(\"âš ï¸ Please upload a Job Description document.\")\n",
        "    elif not resume_files:\n",
        "        st.warning(\"âš ï¸ Please upload at least one candidate resume.\")\n",
        "    else:\n",
        "        status_container = st.container()\n",
        "\n",
        "        try:\n",
        "            with status_container:\n",
        "                st.info(\"ğŸ”„ Initializing AI Engine...\")\n",
        "                st.cache_resource.clear()\n",
        "                system = get_system()\n",
        "\n",
        "            with status_container:\n",
        "                with st.spinner(\"ğŸ“„ Analyzing Job Description...\"):\n",
        "                    job_path = save_uploaded_file(job_file, \"data/job\")\n",
        "                    system.process_job_posting(job_path)\n",
        "                st.success(f\"âœ… Job Processed: **{system.job.job_title}**\")\n",
        "\n",
        "                with st.spinner(f\"ğŸ‘¥ Analyzing {len(resume_files)} Resumes... (This may take a moment)\"):\n",
        "                    resume_paths = [save_uploaded_file(f, \"data/resumes\") for f in resume_files]\n",
        "                    system.process_resumes(resume_paths)\n",
        "                st.success(f\"âœ… {len(system.candidates_db)} Candidates Analyzed\")\n",
        "\n",
        "            with status_container:\n",
        "                with st.spinner(\"ğŸ§  Performing Hybrid Search & Multi-Dimensional Scoring...\"):\n",
        "                    final_reports = system.run_matching_pipeline()\n",
        "\n",
        "            status_container.empty()\n",
        "            st.balloons()\n",
        "\n",
        "            st.subheader(f\"ğŸ† Top Candidates ({len(final_reports)} Matches Found)\")\n",
        "\n",
        "            if not final_reports:\n",
        "                st.error(\"No suitable candidates found based on the current criteria.\")\n",
        "\n",
        "            for i, report in enumerate(final_reports):\n",
        "                score = report.get('final_score', 0)\n",
        "\n",
        "                if score >= 85:\n",
        "                    score_color = \"green\"\n",
        "                    verdict = \"ğŸŒŸ Highly Recommended\"\n",
        "                    border_color = \"#2ecc71\"\n",
        "                elif score >= 70:\n",
        "                    score_color = \"blue\"\n",
        "                    verdict = \"âœ… Recommended\"\n",
        "                    border_color = \"#3498db\"\n",
        "                elif score >= 50:\n",
        "                    score_color = \"orange\"\n",
        "                    verdict = \"âš ï¸ Consider\"\n",
        "                    border_color = \"#f39c12\"\n",
        "                else:\n",
        "                    score_color = \"red\"\n",
        "                    verdict = \"âŒ Not Recommended\"\n",
        "                    border_color = \"#e74c3c\"\n",
        "\n",
        "                with st.container():\n",
        "                    st.markdown(f\"\"\"\n",
        "                    <div class=\"report-card\" style=\"border-left: 5px solid {border_color};\">\n",
        "                        <div style=\"display: flex; justify-content: space-between; align-items: center;\">\n",
        "                            <h3 style=\"margin:0;\">#{i+1} {report.get('name', 'Unknown Candidate')}</h3>\n",
        "                            <div style=\"text-align: right;\">\n",
        "                                <h2 style=\"margin:0; color: {border_color};\">{score:.1f}%</h2>\n",
        "                                <span style=\"background-color: {border_color}; color: white; padding: 2px 8px; border-radius: 10px; font-size: 0.8em;\">{verdict}</span>\n",
        "                            </div>\n",
        "                        </div>\n",
        "                        <p style=\"color: gray; font-size: 0.9em;\">File: {report.get('filename', 'N/A').split('/')[-1]}</p>\n",
        "                    </div>\n",
        "                    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                    tab1, tab2, tab3 = st.tabs([\"ğŸ“ AI Analysis\", \"ğŸ“Š Score Breakdown\", \"ğŸ” Raw Data\"])\n",
        "\n",
        "                    with tab1:\n",
        "                        col1, col2 = st.columns(2)\n",
        "                        with col1:\n",
        "                            st.markdown(\"#### âœ… Strengths\")\n",
        "                            st.info(report.get('strengths', 'No analysis available.'))\n",
        "                        with col2:\n",
        "                            st.markdown(\"#### âš ï¸ Gaps\")\n",
        "                            st.warning(report.get('gaps', 'No analysis available.'))\n",
        "\n",
        "                        st.markdown(\"#### ğŸ’¡ Recommendation\")\n",
        "                        st.success(report.get('notes', 'No recommendation available.'))\n",
        "\n",
        "                    with tab2:\n",
        "                        st.markdown(\"#### Scoring Dimensions\")\n",
        "                        cols = st.columns(3)\n",
        "                        metrics = [\n",
        "                            (\"Must-Have Skills\", int(report.get('must_have_score', 0))),\n",
        "                            (\"Important Skills\", int(report.get('important_score', 0))),\n",
        "                            (\"Experience Match\", int(report.get('experience_score', 0))),\n",
        "                            (\"Recency\", int(report.get('recency_score', 0))),\n",
        "                            (\"Domain Match\", int(report.get('domain_score', 0))),\n",
        "                            (\"Nice-to-Haves\", int(report.get('nice_to_have_score', 0)))\n",
        "                        ]\n",
        "\n",
        "                        for idx, (label, value) in enumerate(metrics):\n",
        "                            with cols[idx % 3]:\n",
        "                                st.metric(label, f\"{value}/100\")\n",
        "                                st.progress(min(value, 100) / 100)\n",
        "\n",
        "                    with tab3:\n",
        "                        st.json(report)\n",
        "\n",
        "                st.write(\"\")\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"An unexpected error occurred: {str(e)}\")\n",
        "            st.exception(e)\n",
        "else:\n",
        "    st.info(\"ğŸ‘ˆ Please upload a Job Description and Candidate Resumes in the sidebar to start.\")\n",
        "\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    with col1:\n",
        "        st.markdown(\"\"\"\n",
        "        ### ğŸ¤– Intelligent Parsing\n",
        "        Uses LLMs to understand context, not just keywords. Extracts implicit skills and domains.\n",
        "        \"\"\")\n",
        "    with col2:\n",
        "        st.markdown(\"\"\"\n",
        "        ### âš–ï¸ Hybrid Retrieval\n",
        "        Combines semantic vector search with traditional keyword matching for best-in-class accuracy.\n",
        "        \"\"\")\n",
        "    with col3:\n",
        "        st.markdown(\"\"\"\n",
        "        ### ğŸ“Š Explainable Scoring\n",
        "        Provides detailed score breakdowns and AI-written explanations for every decision.\n",
        "        \"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF3oUMIRNCPR",
        "outputId": "d36800d3-e276-453d-fb18-0ce5487722bd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create Sample Files**"
      ],
      "metadata": {
        "id": "heRExEcILp2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Creating sample files...\")\n",
        "\n",
        "# Sample Job Posting\n",
        "job_posting_text = \"\"\"\n",
        "Job Posting: Senior Python Developer (FinTech)\n",
        "\n",
        "We are seeking a Senior Python Developer with 5+ years of experience in building\n",
        "scalable web applications for the financial technology (FinTech) sector.\n",
        "The ideal candidate will be an expert in Python and the Django framework.\n",
        "\n",
        "Responsibilities:\n",
        "- Design and develop high-performance, reusable, and reliable Python code.\n",
        "- Mentor junior developers and perform code reviews.\n",
        "- Work with cloud services, preferably AWS.\n",
        "- Build and maintain secure REST APIs.\n",
        "\n",
        "Must-Have Qualifications:\n",
        "- 5+ years of Python experience\n",
        "- 3+ years with Django\n",
        "- Strong knowledge of SQL and PostgreSQL\n",
        "- B.S. in Computer Science\n",
        "\n",
        "Important Qualifications:\n",
        "- Experience with AWS (S3, EC2)\n",
        "- Knowledge of Docker\n",
        "- Experience with REST APIs\n",
        "\n",
        "Nice-to-Have:\n",
        "- Experience with React\n",
        "- Familiarity with CI/CD pipelines\n",
        "\"\"\"\n",
        "with open(\"job_posting.txt\", \"w\") as f: f.write(job_posting_text)\n",
        "\n",
        "# --- Resume 1: Strong Match ---\n",
        "resume_1_text = \"\"\"\n",
        "--- Jane Doe ---\n",
        "Email: jane.doe@example.com\n",
        "\n",
        "Summary:\n",
        "Senior Software Engineer with 8 years of experience specializing in backend\n",
        "development using Python and Django. Proven track record of leading teams\n",
        "and delivering scalable e-commerce and FinTech solutions.\n",
        "\n",
        "Experience:\n",
        "- Senior Developer, FinBank (2019 - Present)\n",
        "  - Led development of a new payment gateway using Python, Django, and PostgreSQL.\n",
        "  - Deployed applications on AWS S3 and EC2.\n",
        "  - Built secure REST APIs for mobile clients.\n",
        "- Developer, TechCorp (2016 - 2019)\n",
        "  - Built internal tools with Python.\n",
        "\n",
        "Education:\n",
        "- B.S. in Computer Science\n",
        "\n",
        "Skills:\n",
        "Python, Django, PostgreSQL, SQL, AWS, S3, EC2, Git, Docker, REST APIs\n",
        "\"\"\"\n",
        "with open(\"resume_strong_match.txt\", \"w\") as f: f.write(resume_1_text)\n",
        "\n",
        "# --- Resume 2: Weak Match (Wrong Domain) ---\n",
        "resume_2_text = \"\"\"\n",
        "--- John Smith ---\n",
        "Email: john.smith@example.com\n",
        "\n",
        "Summary:\n",
        "Frontend Developer with 3 years of experience. Passionate about creating\n",
        "beautiful user interfaces with React. Eager to learn backend technologies.\n",
        "\n",
        "Experience:\n",
        "- Frontend Developer, WebStyles (2021 - Present)\n",
        "  - Built and maintained the company's main website using React and Redux.\n",
        "- Intern, Dev Co (2020)\n",
        "  - Worked with JavaScript and HTML/CSS.\n",
        "\n",
        "Education:\n",
        "- B.A. in Graphic Design\n",
        "\n",
        "Skills:\n",
        "React, JavaScript, HTML, CSS, Redux, Git\n",
        "\"\"\"\n",
        "with open(\"resume_weak_match.txt\", \"w\") as f: f.write(resume_2_text)\n",
        "\n",
        "# --- Resume 3: Borderline Match (Missing Must-Haves) ---\n",
        "resume_3_text = \"\"\"\n",
        "--- Priya Sharma ---\n",
        "Email: priya.sharma@example.com\n",
        "\n",
        "Summary:\n",
        "Data Scientist with 6 years of experience in machine learning and data analysis.\n",
        "Extensive experience with Python and its data stack (Pandas, NumPy).\n",
        "\n",
        "Experience:\n",
        "- Data Scientist, DataAnalytics Inc. (2018 - Present)\n",
        "  - Built ML models using Python, Scikit-learn, and TensorFlow.\n",
        "  - Deployed models on AWS Sagemaker.\n",
        "- Data Analyst, Insights Co. (2016 - 2018)\n",
        "  - Wrote SQL queries and created dashboards.\n",
        "\n",
        "Education:\n",
        "- M.S. in Data Science\n",
        "- B.S. in Computer Science\n",
        "\n",
        "Skills:\n",
        "Python, SQL, Pandas, NumPy, Scikit-learn, TensorFlow, AWS, Sagemaker\n",
        "\"\"\"\n",
        "with open(\"resume_borderline.txt\", \"w\") as f: f.write(resume_3_text)\n",
        "\n",
        "print(\"Sample files created: job_posting.txt, resume_strong_match.txt, resume_weak_match.txt, resume_borderline.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiEe_TAy86Dw",
        "outputId": "42f3274f-9917-4bfb-a8b5-f496baabf4f8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating sample files...\n",
            "Sample files created: job_posting.txt, resume_strong_match.txt, resume_weak_match.txt, resume_borderline.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11. Run the Full End-to-End Pipeline**"
      ],
      "metadata": {
        "id": "-f5OGh-OLw9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import importlib\n",
        "import config\n",
        "import utils\n",
        "import llm_interface\n",
        "import retrieval\n",
        "import scoring\n",
        "import matching_system\n",
        "\n",
        "importlib.reload(config)\n",
        "importlib.reload(utils)\n",
        "importlib.reload(llm_interface)\n",
        "importlib.reload(retrieval)\n",
        "importlib.reload(scoring)\n",
        "importlib.reload(matching_system)\n",
        "\n",
        "from matching_system import CandidateMatchingSystem\n",
        "\n",
        "print(\"--- ğŸš€ STARTING CANDIDATE MATCHING PIPELINE (v2 with ChromaDB & Retries) ğŸš€ ---\")\n",
        "\n",
        "try:\n",
        "    system = CandidateMatchingSystem()\n",
        "\n",
        "    system.process_job_posting(\"job_posting.txt\")\n",
        "    print(\"\\n--- âœ… Job Posting Parsed Successfully ---\")\n",
        "    print(json.dumps(system.job.model_dump(), indent=2))\n",
        "\n",
        "    resume_files = [\"resume_strong_match.txt\", \"resume_weak_match.txt\", \"resume_borderline.txt\"]\n",
        "    system.process_resumes(resume_files)\n",
        "    print(f\"\\n--- âœ… {len(system.candidates_db)} Resumes Parsed Successfully ---\")\n",
        "\n",
        "    final_reports = system.run_matching_pipeline()\n",
        "\n",
        "    print(\"\\n\\n--- ğŸ† FINAL RANKED CANDIDATE REPORT ğŸ† ---\")\n",
        "\n",
        "    for i, report in enumerate(final_reports):\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(f\"      RANK #{i+1} - {report['filename']}\")\n",
        "        print(f\"      CANDIDATE: {report['name']}\")\n",
        "        print(f\"      OVERALL FIT: {report['final_score']}/100\")\n",
        "        print(f\"      CONFIDENCE: {report.get('confidence', 'N/A')}\")\n",
        "        print(\"=\"*50)\n",
        "        print(f\"\\n**Strengths:**\\n{report.get('strengths', 'N/A')}\")\n",
        "        print(f\"\\n**Gaps:**\\n{report.get('gaps', 'N/A')}\")\n",
        "        print(f\"\\n**Notes:**\\n{report.get('notes', 'N/A')}\")\n",
        "        print(\"\\n--- Scoring Breakdown ---\")\n",
        "        print(f\"- Must-Haves: {report['must_have_score']:.0f}/100\")\n",
        "        print(f\"- Important: {report['important_score']:.0f}/100\")\n",
        "        print(f\"- Experience: {report['experience_score']:.0f}/100\")\n",
        "        print(f\"- Recency: {report['recency_score']:.0f}/100\")\n",
        "        print(f\"- Domain: {report['domain_score']:.0f}/100\")\n",
        "        print(\"\\n\" + \"-\"*50)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n--- FATAL ERROR---\")\n",
        "    print(e)\n",
        "\n",
        "print(\"\\n--- ğŸ PIPELINE COMPLETE ğŸ ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVZE0NAx8-5Z",
        "outputId": "d74eedef-f35c-41c7-dcfd-cba9f61eee63"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 'config.py' created.\n",
            "File 'utils.py' created.\n",
            "File 'llm_interface.py' (Final Version with Import Fix) created.\n",
            "File 'retrieval.py' (Upgraded with ChromaDB Fix) created.\n",
            "File 'scoring.py' (Final Version with Corrected Logic) created.\n",
            "File 'matching_system.py' (Final Robust Version) created.\n",
            "--- ğŸš€ STARTING CANDIDATE MATCHING PIPELINE (v2 with ChromaDB & Retries) ğŸš€ ---\n",
            "HybridRetriever initialized with ChromaDB.\n",
            "ScoringEngine initialized.\n",
            "CandidateMatchingSystem initialized.\n",
            "Extracting text from: job_posting.txt\n",
            "LLM Call: Pydantic parsing with mistralai/mistral-7b-instruct:free...\n",
            "Successfully parsed job: Senior Python Developer (FinTech)\n",
            "\n",
            "--- âœ… Job Posting Parsed Successfully ---\n",
            "{\n",
            "  \"job_title\": \"Senior Python Developer (FinTech)\",\n",
            "  \"required_years_experience\": 5,\n",
            "  \"skills\": {\n",
            "    \"must_have\": [\n",
            "      \"Python\",\n",
            "      \"Django\",\n",
            "      \"SQL\",\n",
            "      \"PostgreSQL\",\n",
            "      \"B.S. in Computer Science\"\n",
            "    ],\n",
            "    \"important\": [\n",
            "      \"AWS (S3, EC2)\",\n",
            "      \"Docker\",\n",
            "      \"REST APIs\"\n",
            "    ],\n",
            "    \"nice_to_have\": [\n",
            "      \"React\",\n",
            "      \"CI/CD pipelines\"\n",
            "    ],\n",
            "    \"implicit_skills\": [\n",
            "      \"Scalable web applications\",\n",
            "      \"Code reviews\",\n",
            "      \"Mentoring junior developers\"\n",
            "    ]\n",
            "  },\n",
            "  \"domain_keywords\": [\n",
            "    \"FinTech\"\n",
            "  ],\n",
            "  \"responsibilities_summary\": \"Design and develop high-performance, reusable, and reliable Python code. Mentor junior developers and perform code reviews. Work with cloud services, preferably AWS. Build and maintain secure REST APIs.\"\n",
            "}\n",
            "Starting processing for 3 resumes...\n",
            "Processing file: resume_strong_match.txt\n",
            "Extracting text from: resume_strong_match.txt\n",
            "LLM Call: Pydantic parsing with mistralai/mistral-7b-instruct:free...\n",
            "Successfully parsed: resume_strong_match.txt\n",
            "Processing file: resume_weak_match.txt\n",
            "Extracting text from: resume_weak_match.txt\n",
            "LLM Call: Pydantic parsing with mistralai/mistral-7b-instruct:free...\n",
            "Successfully parsed: resume_weak_match.txt\n",
            "Processing file: resume_borderline.txt\n",
            "Extracting text from: resume_borderline.txt\n",
            "LLM Call: Pydantic parsing with mistralai/mistral-7b-instruct:free...\n",
            "Successfully parsed: resume_borderline.txt\n",
            "Successfully parsed 3 out of 3 resumes.\n",
            "\n",
            "--- âœ… 3 Resumes Parsed Successfully ---\n",
            "Indexing 3 documents...\n",
            "Indexing complete.\n",
            "Running hybrid search for query: Design and develop high-performance, reusable, and...\n",
            "BM25 found IDs: ['resume_borderline.txt', 'resume_strong_match.txt', 'resume_weak_match.txt']\n",
            "ChromaDB found IDs: ['resume_strong_match.txt', 'resume_borderline.txt', 'resume_weak_match.txt']\n",
            "Retrieval found 3 unique candidates for re-ranking.\n",
            "Re-ranking 3 candidates...\n",
            "Re-ranking candidate: Priya Sharma\n",
            "Re-ranking candidate: John Smith\n",
            "Re-ranking candidate: Jane Doe\n",
            "LLM Call: Generative explanation with mistralai/mistral-7b-instruct:free...\n",
            "LLM Call: Generative explanation with mistralai/mistral-7b-instruct:free...\n",
            "LLM Call: Generative explanation with mistralai/mistral-7b-instruct:free...\n",
            "\n",
            "\n",
            "--- ğŸ† FINAL RANKED CANDIDATE REPORT ğŸ† ---\n",
            "\n",
            "==================================================\n",
            "      RANK #1 - resume_strong_match.txt\n",
            "      CANDIDATE: Jane Doe\n",
            "      OVERALL FIT: 90.0/100\n",
            "      CONFIDENCE: High\n",
            "==================================================\n",
            "\n",
            "**Strengths:**\n",
            "The candidate has a perfect match on all key dimensions (Must-Have, Important, Experience, Recency, and Domain). They have 8 years of Python/Django experience, leadership skills, and expertise in building scalable solutions, which aligns perfectly with the job requirements.\n",
            "\n",
            "**Gaps:**\n",
            "No significant gaps identified. The slight deviation from 100/100 may be due to minor differences in specific cloud service (AWS) experience or REST API depth, but these are likely negligible given the candidate's strong background.\n",
            "\n",
            "**Notes:**\n",
            "This candidate is an excellent fit for the role. Their senior-level experience, mentorship capabilities, and alignment with the job requirements make them a top contender. Recommend moving forward with an interview to assess cultural fit and specific AWS expertise.\n",
            "\n",
            "--- Scoring Breakdown ---\n",
            "- Must-Haves: 100/100\n",
            "- Important: 100/100\n",
            "- Experience: 100/100\n",
            "- Recency: 100/100\n",
            "- Domain: 100/100\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "==================================================\n",
            "      RANK #2 - resume_borderline.txt\n",
            "      CANDIDATE: Priya Sharma\n",
            "      OVERALL FIT: 61.33/100\n",
            "      CONFIDENCE: Moderate\n",
            "==================================================\n",
            "\n",
            "**Strengths:**\n",
            "The candidate has strong Python experience, extensive data science background, and recent relevant experience. They score highly on experience and recency.\n",
            "\n",
            "**Gaps:**\n",
            "Lacks direct experience in cloud services (AWS), REST API development, and mentoring junior developers. No domain experience in software engineering or backend development.\n",
            "\n",
            "**Notes:**\n",
            "While the candidate has impressive technical skills in Python and data science, their background does not align well with the job's focus on cloud services, API development, and mentorship. They may require significant training in these areas. Consider if the role can accommodate a data science focus or if the candidate is open to upskilling in the required domains.\n",
            "\n",
            "--- Scoring Breakdown ---\n",
            "- Must-Haves: 80/100\n",
            "- Important: 33/100\n",
            "- Experience: 100/100\n",
            "- Recency: 100/100\n",
            "- Domain: 0/100\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "==================================================\n",
            "      RANK #3 - resume_weak_match.txt\n",
            "      CANDIDATE: John Smith\n",
            "      OVERALL FIT: 24.0/100\n",
            "      CONFIDENCE: low\n",
            "==================================================\n",
            "\n",
            "**Strengths:**\n",
            "Recent experience in frontend development with React and eagerness to learn backend technologies.\n",
            "\n",
            "**Gaps:**\n",
            "Lacks experience in Python, cloud services (AWS), REST API development, and mentoring junior developers. No direct backend or Python experience.\n",
            "\n",
            "**Notes:**\n",
            "The candidate's frontend expertise does not align with the job's backend and Python requirements. While they show interest in backend technologies, they lack the necessary experience in the must-have skills for this role.\n",
            "\n",
            "--- Scoring Breakdown ---\n",
            "- Must-Haves: 0/100\n",
            "- Important: 0/100\n",
            "- Experience: 60/100\n",
            "- Recency: 100/100\n",
            "- Domain: 0/100\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- ğŸ PIPELINE COMPLETE ğŸ ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok -q\n"
      ],
      "metadata": {
        "id": "XxDZ1nOLCQSu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Run the Streamlit UI with ngrok**"
      ],
      "metadata": {
        "id": "wN0ECUBnMizz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.set_auth_token(\"Your Ngrok_Authtoken here...\")\n",
        "\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "print(f\"ğŸš€ Your App is Live at: {public_url}\")\n",
        "\n",
        "!streamlit run app.py >/dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ_bczocCOEz",
        "outputId": "9979446e-f124-4ef6-9b64-2cd44bc0de45"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Your App is Live at: https://sadye-openchain-primely.ngrok-free.dev\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-11-18T11:23:09+0000 lvl=warn msg=\"failed to open private leg\" id=f1d940f35744 privaddr=localhost:8501 err=\"dial tcp [::1]:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-11-18T11:23:10+0000 lvl=warn msg=\"failed to open private leg\" id=7a4e5f9974fe privaddr=localhost:8501 err=\"dial tcp [::1]:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-11-18T11:23:10+0000 lvl=warn msg=\"failed to open private leg\" id=f1c53d21d283 privaddr=localhost:8501 err=\"dial tcp [::1]:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-11-18T11:23:10+0000 lvl=warn msg=\"failed to open private leg\" id=5305ff71c2d1 privaddr=localhost:8501 err=\"dial tcp [::1]:8501: connect: connection refused\"\n"
          ]
        }
      ]
    }
  ]
}